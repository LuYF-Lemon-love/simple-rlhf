# simple-rlhf

## 参考

[1] [ChatGPT 背后的“功臣”——RLHF 技术详解](https://huggingface.co/blog/zh/rlhf)

[2] [ChatGPT技术解析系列之：训练框架InstructGPT](https://zhuanlan.zhihu.com/p/605516116)

[3] [DeepSpeed-Chat arxiv](https://arxiv.org/abs/2308.01320)

[4] [DeepSpeed-Chat pdf](https://arxiv.org/pdf/2308.01320.pdf)

[5] [DeepSpeed Chat: 一键式RLHF训练，让你的类ChatGPT千亿大模型提速省钱15倍](https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-chat/chinese/README.md)

[6] [相对熵](https://baike.baidu.com/item/%E7%9B%B8%E5%AF%B9%E7%86%B5/4233536)

[7] [KL散度和交叉熵的对比介绍](https://baijiahao.baidu.com/s?id=1763841223452070719)

[8] [sunzeyeah/RLHF](https://github.com/sunzeyeah/RLHF)

[9] [DeepSpeed Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales](https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat)

[10] [microsoft/DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples)

[11] [🐕DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales🐕](https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat)

[12] [argparse.html#nargs](https://docs.python.org/zh-cn/3/library/argparse.html#nargs)

[13] [timedelta 类对象](https://docs.python.org/zh-cn/3/library/datetime.html#datetime.timedelta)

[14] [subprocess.Popen](https://docs.python.org/zh-cn/3/library/subprocess.html#subprocess.Popen)

[15] [Popen.wait](https://docs.python.org/zh-cn/3/library/subprocess.html#subprocess.Popen.wait)